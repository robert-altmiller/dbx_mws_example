name: Deploy Infrastructure

on:
  workflow_dispatch:
    inputs:
      ENVIRONMENT: # variable
        description: 'Deploy Environment (dev/prod)'
        required: true
        default: '[dev],prod' # install chrome extension for drop down menu (see readme)
      DEPLOY_CLUSTERS: # variable
        description: 'Create Clusters (true/false/destroy)'
        required: true
        default: '[false],true,destroy' # install chrome extension for drop down menu (see readme)
      DEPLOY_CLUSTER_POLICIES: # variable
        description: 'Create Cluster Policies (true/false/destroy)'
        required: true
        default: '[false],true,destroy' # install chrome extension for drop down menu (see readme)
      DEPLOY_UC_STORAGE_CRED: # variable
        description: 'Create UC Storage Credential (true/false/destroy)'
        required: true
        default: '[false],true,destroy' # install chrome extension for drop down menu (see readme)
      DEPLOY_UC_EXTERNAL_LOC: # variable
        description: 'Create UC External Location (true/false/destroy)'
        required: true
        default: '[false],true,destroy' # install chrome extension for drop down menu (see readme)
      DEPLOY_UC_CATALOG: # variable
        description: 'Create UC Catalog (true/false/destroy)'
        required: true
        default: '[false],true,destroy' # install chrome extension for drop down menu (see readme)
      DEPLOY_UC_SCHEMA: # variable
        description: 'Create UC Schema (true/false/destroy)'
        required: true
        default: '[false],true,destroy' # install chrome extension for drop down menu (see readme)
      DEPLOY_DELTA_SHARE: # variable
        description: 'Create Delta Share (true/false/destroy)'
        required: true
        default: '[false],true,destroy' # install chrome extension for drop down menu (see readme)

jobs:
  deploy:
    name: 'Terraform Plan and Apply'
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./repo

    env:
      TF_VAR_environment: ${{ github.event.inputs.ENVIRONMENT || secrets.ENVIRONMENT  }}
      TF_VAR_aws_account_id: ${{ secrets.AWS_ACCOUNT_ID }}
      TF_VAR_aws_region: ${{ secrets.AWS_REGION }}
      TF_VAR_aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
      TF_VAR_aws_access_key_secret: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      TF_VAR_databricks_account_id: ${{ secrets.DATABRICKS_ACCOUNT_ID }}
      TF_VAR_databricks_instances: '{"dev": "${{ secrets.DATABRICKS_INSTANCE_DEV }}", "prod": "${{ secrets.DATABRICKS_INSTANCE_PROD }}"}'
      TF_VAR_databricks_client_ids: '{"dev": "${{ secrets.DATABRICKS_CLIENT_ID_DEV }}", "prod": "${{ secrets.DATABRICKS_CLIENT_ID_PROD }}"}'
      TF_VAR_databricks_client_secrets: '{"dev": "${{ secrets.DATABRICKS_CLIENT_ID_SECRET_DEV }}", "prod": "${{ secrets.DATABRICKS_CLIENT_ID_SECRET_PROD }}"}'
      # TF_VAR_databricks_admin_login: ${{ secrets.DATABRICKS_ADMIN_LOGIN }}
      # TF_VAR_databricks_admin_password: ${{ secrets.DATABRICKS_ADMIN_PASSWORD }}
      TF_VAR_github_actor: ${{ github.actor }} # username for tagging of resources
      # for env vars below default to 'false' if running directly from push to main branch so we execute a simple workflow run unit test
      # if running workflow manually then you can deploy these items below
      databricks_deploy_clusters: ${{ github.event.inputs.DEPLOY_CLUSTERS || 'false' }}
      databricks_deploy_cluster_policies: ${{ github.event.inputs.DEPLOY_CLUSTER_POLICIES || 'false' }}
      databricks_deploy_uc_storage_credential: ${{ github.event.inputs.DEPLOY_UC_STORAGE_CRED || 'false' }}
      databricks_deploy_uc_external_location: ${{ github.event.inputs.DEPLOY_UC_EXTERNAL_LOC || 'false' }}
      databricks_deploy_uc_catalog: ${{ github.event.inputs.DEPLOY_UC_CATALOG || 'false' }}
      databricks_deploy_uc_schema: ${{ github.event.inputs.DEPLOY_UC_SCHEMA || 'false' }}
      databricks_deploy_delta_share: ${{ github.event.inputs.DEPLOY_DELTA_SHARE || 'false' }}

    steps:

      - uses: actions/checkout@v3
        with:
          token: ${{ secrets.GH_TOKEN }}
    

      - name: Set up latest version of Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install jq
        run: sudo apt-get install jq


      - name: Create Terraform Init Backend Configuration
        run: |
          BACKEND_BUCKET_UC=$(jq -r .backend_bucket_uc < ./databricks_dev/tf_s3_backend_config.json)
          BACKEND_BUCKET_DEV=$(jq -r .backend_bucket_dev < ./databricks_dev/tf_s3_backend_config.json)
          BACKEND_BUCKET_PROD=$(jq -r .backend_bucket_prod < ./databricks_dev/tf_s3_backend_config.json)
          echo "BACKEND_BUCKET_UC=$BACKEND_BUCKET_UC" >> $GITHUB_ENV
          echo "BACKEND_BUCKET_DEV=$BACKEND_BUCKET_DEV" >> $GITHUB_ENV
          echo "BACKEND_BUCKET_PROD=$BACKEND_BUCKET_PROD" >> $GITHUB_ENV
          echo "BACKEND_BUCKET_UC: $BACKEND_BUCKET_UC"
          echo "BACKEND_BUCKET_DEV: $BACKEND_BUCKET_DEV"
          echo "BACKEND_BUCKET_PROD: $BACKEND_BUCKET_PROD"


      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1


      - name: Setup Terraform Init Backend
        run: |
          export TF_LOG=DEBUG
          if [ "${{ env.TF_VAR_environment }}" == "unity_catalog" ]; then
            export BUCKET_NAME="${{ env.BACKEND_BUCKET_UC }}"
          elif [ "${{ env.TF_VAR_environment }}" == "dev" ]; then
            export BUCKET_NAME="${{ env.BACKEND_BUCKET_DEV }}"
          else
            export BUCKET_NAME="${{ env.BACKEND_BUCKET_PROD }}"
          fi
          echo BUCKET_NAME: $BUCKET_NAME
          export KEY_NAME="terraform/terraform.tfstate"
          export AWS_REGION="${{ env.TF_VAR_aws_region }}"
          export ACCESS_KEY="${{ env.TF_VAR_aws_access_key_id }}"
          export SECRET_KEY="${{ env.TF_VAR_aws_access_key_secret}}"
          chmod +x ./databricks_dev/tf_s3_backend_deploy.sh
          cd ./databricks_dev
          ./tf_s3_backend_deploy.sh


      - name: Update Terraform Deploy Environment Variable
        run: |
          if [[ "${{ env.TF_VAR_environment }}" == "unity_catalog" ]]; then
          export TF_VAR_environment="dev"
          fi
          echo "TF_VAR_environment=$TF_VAR_environment" >> $GITHUB_ENV
        shell: bash


      - name: Get Databricks Authentication Token
        run: |
          export DATABRICKS_ACCOUNT_ID="${{ env.TF_VAR_databricks_account_id }}"
          export DATABRICKS_CLIENT_ID=$(echo $TF_VAR_databricks_client_ids | jq -r .${{env.TF_VAR_environment}})
          export DATABRICKS_CLIENT_SECRET=$(echo $TF_VAR_databricks_client_secrets | jq -r .${{env.TF_VAR_environment}})
          pip3 install -r ./common_code/python/requirements.txt
          chmod +x ./common_code/python/get_databricks_token.py
          TF_VAR_databricks_token=$(python3 ./common_code/python/get_databricks_token.py)
          echo "TF_VAR_databricks_token=$TF_VAR_databricks_token" >> $GITHUB_ENV
          echo "TF_VAR_databricks_token: $TF_VAR_databricks_token"


      - name: Terraform Init
        run: |
          export TF_LOG=DEBUG
          terraform init
        working-directory: ./databricks_dev

          
      # - name: Terraform Validate
      #   run: |
      #     export TF_LOG=DEBUG
      #     terraform validate
  
  
      - name: Terraform Plan
        run: |
          export TF_LOG=DEBUG
          terraform plan
        working-directory: ./databricks_dev


      # - name: Terraform Apply
      #   run: |
      #     export TF_LOG=DEBUG
      #     terraform apply
